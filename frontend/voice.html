<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<title>GalaxyX ‚Äî Jarvis Voice Mode</title>
<style>
  :root{
    --bg:#000811;
    --neon:#00e0ff;
    --neon-2:#4cffb1;
    --muted:#8b98a8;
    --glass:rgba(255,255,255,0.03);
    --accent-glow: 0 10px 40px rgba(0,224,255,0.08);
    --glass-2: rgba(255,255,255,0.02);
    font-family: Inter, system-ui, sans-serif;
  }
  html,body{height:100%;margin:0;background:linear-gradient(180deg,#000814, #00020a 80%);color:#dff7ff;overflow:hidden}
  .jarvis{
    width:100vw;height:100vh;display:flex;flex-direction:column;align-items:center;justify-content:space-between;padding:36px;
    background-image: radial-gradient( circle at 10% 10%, rgba(0,224,255,0.03), transparent 20%),
                      radial-gradient( circle at 90% 90%, rgba(76,255,177,0.02), transparent 20%);
  }

  header{width:100%;display:flex;justify-content:space-between;align-items:center}
  .brand{display:flex;gap:12px;align-items:center}
  .logo{
    width:56px;height:56px;border-radius:12px;background:linear-gradient(135deg,var(--neon),#0064b8);
    display:flex;align-items:center;justify-content:center;font-weight:800;font-size:20px;box-shadow:var(--accent-glow);
  }
  .title{font-size:20px;font-weight:600}
  .sub{color:var(--muted);font-size:13px}

  .center{
    display:flex;flex-direction:column;align-items:center;gap:18px;margin-top:20px;
  }

  /* HUD Circle */
  .hud{
    width:420px;height:420px;border-radius:50%;display:flex;align-items:center;justify-content:center;
    background:conic-gradient(rgba(0,224,255,0.02), transparent 40%);
    border:1px solid rgba(0,224,255,0.06);
    box-shadow:0 30px 80px rgba(0,0,0,0.6);
    position:relative;
    overflow:visible;
  }

  .hud .core{
    width:220px;height:220px;border-radius:50%;display:flex;align-items:center;justify-content:center;
    background:linear-gradient(180deg, rgba(0,224,255,0.06), rgba(76,255,177,0.03));
    border:1px solid rgba(0,224,255,0.12);
    box-shadow: 0 12px 32px rgba(0,224,255,0.06);
    backdrop-filter: blur(6px);
    text-align:center;padding:18px;
    color:#e8ffff;
    font-weight:600;
  }

  .core .status{font-size:20px;margin-bottom:8px}
  .core .phase{font-size:13px;color:var(--muted)}

  /* waveform canvas overlay */
  canvas#wave{position:absolute;inset:0;width:100%;height:100%;pointer-events:none}

  /* small caption area */
  .caption{
    margin-top:10px;
    min-width:640px;max-width:880px;padding:14px;border-radius:12px;background:var(--glass-2);
    border:1px solid rgba(0,224,255,0.04);text-align:center;color:#bfeff7;font-size:15px;
  }

  /* controls */
  .controls{display:flex;gap:14px;align-items:center;margin-bottom:6px}
  .btn{
    padding:12px 18px;border-radius:12px;background:transparent;border:1px solid rgba(255,255,255,0.06);
    color:#dff7ff;cursor:pointer;font-weight:600;
  }
  .btn.neon{
    background:linear-gradient(90deg,var(--neon),var(--neon-2));
    color:#00201f;border:none;box-shadow:0 10px 40px rgba(0,224,255,0.08);
  }
  .btn.warn{background:#ff4d4d;color:white;border:none}

  /* transcript list */
  .transcript{
    position:fixed;right:28px;top:120px;width:320px;max-height:70vh;overflow:auto;padding:12px;border-radius:12px;
    background:linear-gradient(180deg, rgba(255,255,255,0.02), transparent);
    border:1px solid rgba(255,255,255,0.03);font-size:13px;color:#c8f8ff;
  }
  .transcript .line{padding:8px;border-bottom:1px dashed rgba(255,255,255,0.02)}
  .transcript .you{color:#b8e7ff}
  .transcript .ai{color:#aef1c2}

  /* back button */
  .back{position:fixed;left:28px;top:28px;padding:10px 12px;border-radius:10px;background:transparent;border:1px solid rgba(255,255,255,0.04);cursor:pointer}

  @media(max-width:900px){
    .hud{width:320px;height:320px}
    .caption{min-width:320px}
    .transcript{display:none}
  }
</style>
</head>
<body>
<div class="jarvis">
  <header>
    <div class="brand">
      <div class="logo">X</div>
      <div>
        <div class="title">GalaxyX ‚Äî JARVIS Mode</div>
        <div class="sub">Voice-first assistant ‚Ä¢ Neon HUD</div>
      </div>
    </div>

    <div style="display:flex;gap:10px;align-items:center">
      <div class="sub">Status: <span id="globalState">Idle</span></div>
    </div>
  </header>

  <div class="center">
    <div class="hud" id="hud">
      <canvas id="wave"></canvas>

      <div class="core" id="core">
        <div class="status" id="statusText">Tap ‚ñ∂ to speak</div>
        <div class="phase" id="phaseText">Idle</div>
      </div>
    </div>

    <div class="caption" id="caption">Say something like: "Hey Jarvis, what's the weather?"</div>

    <div class="controls">
      <button class="btn neon" id="startBtn">‚ñ∂ Speak</button>
      <button class="btn" id="stopBtn">‚ñ† Stop</button>
      <button class="btn" id="alwaysBtn">üîÅ Auto Listen: Off</button>
      <button class="btn warn" id="exitBtn">Exit</button>
    </div>
  </div>

  <div style="height:18px"></div>

  <div class="transcript" id="transcript">
    <div style="font-weight:700;margin-bottom:8px">Conversation</div>
  </div>

  <button class="back" id="backBtn">‚Üê Back</button>
</div>

<script>
/* CONFIG ‚Äî change endpoints if needed */
const BASE = "https://galaxy-ai-3.onrender.com"; // change to your host if local
const ENDPOINT_STT = BASE + "/stt";
const ENDPOINT_CHAT = BASE + "/chat";
const ENDPOINT_TTS = BASE + "/tts";

/* UI */
const startBtn = document.getElementById("startBtn");
const stopBtn  = document.getElementById("stopBtn");
const alwaysBtn = document.getElementById("alwaysBtn");
const exitBtn  = document.getElementById("exitBtn");
const backBtn  = document.getElementById("backBtn");
const statusText = document.getElementById("statusText");
const phaseText = document.getElementById("phaseText");
const caption = document.getElementById("caption");
const transcript = document.getElementById("transcript");
const globalState = document.getElementById("globalState");

/* audio & recorder */
let mediaStream = null;
let recorder = null;
let chunks = [];
let audioContext = null;
let analyser = null;
let dataArray = null;
let rafId = null;
let autoListen = false;
let isRecording = false;

/* waveform canvas */
const canvas = document.getElementById("wave");
const ctx = canvas.getContext("2d");
function resizeCanvas(){
  canvas.width = canvas.clientWidth;
  canvas.height = canvas.clientHeight;
}
window.addEventListener("resize", resizeCanvas);
resizeCanvas();

/* draw waveform */
function startVisuals(){
  if(!audioContext) return;
  analyser.fftSize = 2048;
  const bufferLength = analyser.fftSize;
  dataArray = new Uint8Array(bufferLength);

  function draw(){
    rafId = requestAnimationFrame(draw);
    analyser.getByteTimeDomainData(dataArray);
    ctx.clearRect(0,0,canvas.width,canvas.height);

    ctx.lineWidth = 2;
    ctx.strokeStyle = "rgba(0,224,255,0.9)";
    ctx.beginPath();

    const sliceWidth = canvas.width * 1.0 / bufferLength;
    let x = 0;
    for(let i=0;i<bufferLength;i++){
      const v = dataArray[i] / 128.0;
      const y = v * canvas.height/2;
      if(i===0) ctx.moveTo(x,y);
      else ctx.lineTo(x,y);
      x += sliceWidth;
    }
    ctx.lineTo(canvas.width, canvas.height/2);
    ctx.stroke();

    // outer glow rings (reactive)
    const rms = dataArray.reduce((a,b)=>a+Math.abs(b-128),0)/bufferLength;
    const scale = 1 + rms/400;
    document.getElementById("hud").style.transform = `scale(${1 + (rms/10000)})`;
  }
  draw();
}

function stopVisuals(){
  if(rafId) cancelAnimationFrame(rafId);
  ctx.clearRect(0,0,canvas.width,canvas.height);
  if(document.getElementById("hud")) document.getElementById("hud").style.transform = "";
}

/* utility: push transcript */
function pushTranscript(role, text){
  const d = document.createElement("div");
  d.className = "line " + (role==="user"?"you":"ai");
  d.innerHTML = `<strong>${role==="user"?"You":"GalaxyX"}:</strong> ${text}`;
  transcript.appendChild(d);
  transcript.scrollTop = transcript.scrollHeight;
}

/* start recording */
async function startRecording(maxMs=8000){
  if(isRecording) return;
  isRecording = true;
  globalState.textContent = "Listening";
  statusText.textContent = "Listening...";
  phaseText.textContent = "Recording audio";

  try{
    mediaStream = await navigator.mediaDevices.getUserMedia({ audio:true });
  } catch (e){
    alert("Mic access denied or unavailable: " + e.message);
    isRecording = false;
    globalState.textContent = "Idle";
    statusText.textContent = "Tap ‚ñ∂ to speak";
    phaseText.textContent = "Idle";
    return;
  }

  audioContext = new (window.AudioContext || window.webkitAudioContext)();
  const source = audioContext.createMediaStreamSource(mediaStream);
  analyser = audioContext.createAnalyser();
  source.connect(analyser);
  startVisuals();

  recorder = new MediaRecorder(mediaStream, { mimeType: 'audio/webm' });
  chunks = [];
  recorder.ondataavailable = e => { if(e.data.size>0) chunks.push(e.data); };
  recorder.onstop = async () => {
    stopVisuals();
    isRecording = false;
    globalState.textContent = "Processing";
    statusText.textContent = "Processing audio...";
    phaseText.textContent = "Transcribing (STT)";

    const blob = new Blob(chunks, { type: 'audio/webm' });
    try{
      const fd = new FormData();
      fd.append("audio", blob, "voice.webm");
      const sttResp = await fetch(ENDPOINT_STT, { method:"POST", body:fd });
      const sttJson = await sttResp.json();
      const userText = sttJson.text || "";

      if(!userText){
        statusText.textContent = "Didn't hear anything";
        phaseText.textContent = "Idle";
        globalState.textContent = "Idle";
        caption.textContent = "No speech detected. Try again.";
        if(autoListen) setTimeout(()=>startRecording(8000), 600);
        return;
      }

      pushTranscript("user", userText);
      caption.textContent = `You said: "${userText}"`;
      statusText.textContent = "Thinking...";
      phaseText.textContent = "Awaiting AI reply";
      globalState.textContent = "Thinking";

      // call chat
      const chatRes = await fetch(ENDPOINT_CHAT, {
        method:"POST",headers:{"Content-Type":"application/json"},
        body: JSON.stringify({ text: userText })
      });
      const chatJson = await chatRes.json();
      const aiReply = chatJson.reply || "Sorry, I couldn't reply.";

      pushTranscript("ai", aiReply);
      caption.textContent = aiReply;
      statusText.textContent = "Speaking...";
      phaseText.textContent = "Generating audio";
      globalState.textContent = "Speaking";

      // call tts to get audio blob
      const ttsRes = await fetch(ENDPOINT_TTS, {
        method:"POST",headers:{"Content-Type":"application/json"},
        body: JSON.stringify({ text: aiReply })
      });
      const audioBlob = await ttsRes.blob();
      const url = URL.createObjectURL(audioBlob);
      const audio = new Audio(url);
      audio.onended = () => {
        statusText.textContent = "Idle";
        phaseText.textContent = "Idle";
        globalState.textContent = "Idle";
        if(autoListen) setTimeout(()=>startRecording(8000), 600);
      };
      audio.play();
    } catch (err) {
      console.error(err);
      statusText.textContent = "Error";
      phaseText.textContent = err.message || "Network error";
      globalState.textContent = "Error";
      if(autoListen) setTimeout(()=>startRecording(8000), 1000);
    } finally {
      // cleanup audio resources
      try{ if(mediaStream){ mediaStream.getTracks().forEach(t=>t.stop()); } } catch(e){}
      try{ if(audioContext) audioContext.close(); } catch(e){}
      mediaStream = null; recorder = null; analyser = null; audioContext = null;
    }
  };

  recorder.start();
  // auto-stop after maxMs
  setTimeout(()=>{ if(recorder && recorder.state === "recording") recorder.stop(); }, maxMs);
}

/* stop recording immediately */
function stopRecordingNow(){
  if(recorder && recorder.state === "recording") recorder.stop();
  if(mediaStream) mediaStream.getTracks().forEach(t=>t.stop());
  stopVisuals();
  isRecording = false;
  globalState.textContent = "Idle";
  statusText.textContent = "Idle";
  phaseText.textContent = "Idle";
}

/* UI events */
startBtn.onclick = ()=> startRecording(8000);
stopBtn.onclick  = ()=> stopRecordingNow();

alwaysBtn.onclick = ()=>{
  autoListen = !autoListen;
  alwaysBtn.textContent = autoListen ? "üîÅ Auto Listen: On" : "üîÅ Auto Listen: Off";
  alwaysBtn.classList.toggle("neon", autoListen);
  if(autoListen && !isRecording) startRecording(8000);
};

exitBtn.onclick = ()=> {
  stopRecordingNow();
  window.close(); // may be blocked by browser if not opened by script
  // fallback: go back to main
  window.location.href = "index.html";
};
backBtn.onclick = ()=> {
  stopRecordingNow();
  window.location.href = "index.html";
};

/* keyboard shortcuts */
document.addEventListener("keydown", (e)=>{
  if(e.key === "Escape") { stopRecordingNow(); }
  if(e.key === " ") { // space to start/stop
    e.preventDefault();
    if(isRecording) stopRecordingNow();
    else startRecording(8000);
  }
});

/* init: small pulse animation */
(function init(){
  caption.textContent = "Press ‚ñ∂ to start Jarvis. Tip: turn speaker on for responses.";
})();
</script>
</body>
</html>
