<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<title>GalaxyX ‚Äî Jarvis Voice Mode</title>

<style>
  :root{
    --bg:#000811;
    --neon:#00e0ff;
    --neon-2:#4cffb1;
    --muted:#8b98a8;
    --glass:rgba(255,255,255,0.03);
    --accent-glow: 0 10px 40px rgba(0,224,255,0.08);
    --glass-2: rgba(255,255,255,0.02);
    font-family: Inter, system-ui, sans-serif;
  }
  html,body{
    height:100%;
    margin:0;
    background:linear-gradient(180deg,#000814,#00020a 80%);
    color:#dff7ff;
    overflow:hidden;
  }

  .jarvis{
    width:100vw;height:100vh;
    display:flex;flex-direction:column;
    align-items:center;justify-content:space-between;
    padding:36px;
    background-image:
      radial-gradient(circle at 10% 10%, rgba(0,224,255,0.04), transparent 20%),
      radial-gradient(circle at 90% 90%, rgba(76,255,177,0.03), transparent 20%);
  }

  header{
    width:100%;
    display:flex;justify-content:space-between;align-items:center;
  }

  .brand{display:flex;gap:12px;align-items:center}
  .logo{
    width:56px;height:56px;border-radius:12px;
    background:linear-gradient(135deg,var(--neon),#0064b8);
    display:flex;align-items:center;justify-content:center;
    font-size:22px;font-weight:800;
    box-shadow:var(--accent-glow);
  }
  .title{font-size:20px;font-weight:600}
  .sub{font-size:13px;color:var(--muted)}

  .center{
    display:flex;flex-direction:column;align-items:center;gap:18px;
  }

  /* RESPONSIVE HUD */
  .hud{
    width:min(80vw,380px);
    height:min(80vw,380px);
    border-radius:50%;
    display:flex;align-items:center;justify-content:center;
    background:conic-gradient(rgba(0,224,255,0.03), transparent 40%);
    border:1px solid rgba(0,224,255,0.06);
    box-shadow:0 30px 80px rgba(0,0,0,0.6);
    position:relative;
  }

  .core{
    width:min(48vw,200px);
    height:min(48vw,200px);
    border-radius:50%;
    display:flex;align-items:center;justify-content:center;
    flex-direction:column;
    background:linear-gradient(180deg,rgba(0,224,255,0.05),rgba(76,255,177,0.03));
    border:1px solid rgba(0,224,255,0.12);
    backdrop-filter:blur(6px);
    text-align:center;
    padding:18px;
    color:#e8ffff;
  }

  .status{font-size:18px;margin-bottom:6px}
  .phase{font-size:12px;color:var(--muted)}

  canvas#wave{
    position:absolute;inset:0;width:100%;height:100%;
    pointer-events:none;
  }

  /* Responsive caption */
  .caption{
    width:90vw;
    max-width:900px;
    padding:14px;
    border-radius:12px;
    background:var(--glass-2);
    border:1px solid rgba(0,224,255,0.04);
    text-align:center;
    font-size:15px;
    color:#bfeff7;
  }

  /* controls */
  .controls{display:flex;gap:14px;margin-top:10px}
  .btn{
    padding:12px 18px;border-radius:12px;
    border:1px solid rgba(255,255,255,0.06);
    background:transparent;color:#dff7ff;
    cursor:pointer;font-weight:600;
  }
  .btn.neon{
    background:linear-gradient(90deg,var(--neon),var(--neon-2));
    border:none;color:#001615;
  }
  .btn.warn{background:#ff4d4d;border:none;color:white}

  .transcript{
    position:fixed;right:20px;top:120px;
    width:300px;max-height:65vh;
    padding:12px;border-radius:12px;
    overflow:auto;
    font-size:13px;
    background:rgba(255,255,255,0.02);
    border:1px solid rgba(255,255,255,0.03);
  }

  .line{padding:8px;border-bottom:1px dashed rgba(255,255,255,0.05)}
  .you{color:#b8e7ff}
  .ai{color:#baffc7}

  .back{
    position:fixed;left:18px;top:20px;
    padding:10px 12px;border-radius:10px;
    border:1px solid rgba(255,255,255,0.04);
    background:transparent;color:#dff7ff;
    cursor:pointer;
  }

  @media(max-width:900px){
    .transcript{display:none}
  }
</style>
</head>

<body>
<div class="jarvis">
  
  <header>
    <div class="brand">
      <div class="logo">X</div>
      <div>
        <div class="title">GalaxyX ‚Äî JARVIS Mode</div>
        <div class="sub">Voice-first assistant ‚Ä¢ Neon HUD</div>
      </div>
    </div>
    <div class="sub">Status: <span id="globalState">Idle</span></div>
  </header>

  <div class="center">
    <div class="hud" id="hud">
      <canvas id="wave"></canvas>

      <div class="core" id="core">
        <div class="status" id="statusText">Tap ‚ñ∂ to speak</div>
        <div class="phase" id="phaseText">Idle</div>
      </div>
    </div>

    <div class="caption" id="caption">
      Say something like: ‚ÄúHey GalaxyX, what can you do?‚Äù
    </div>

    <div class="controls">
      <button class="btn neon" id="startBtn">‚ñ∂ Speak</button>
      <button class="btn" id="stopBtn">‚ñ† Stop</button>
      <button class="btn" id="alwaysBtn">üîÅ Auto Listen: Off</button>
      <button class="btn warn" id="exitBtn">Exit</button>
    </div>
  </div>

  <div class="transcript" id="transcript">
    <div style="font-weight:700;margin-bottom:6px">Conversation</div>
  </div>

  <button class="back" id="backBtn">‚Üê Back</button>
</div>

<script>
/* ENDPOINTS */
const BASE = "https://galaxy-ai-3.onrender.com";
const ENDPOINT_STT = BASE + "/stt";
const ENDPOINT_CHAT = BASE + "/chat";
const ENDPOINT_TTS = BASE + "/tts";

/* UI elements */
const startBtn = document.getElementById("startBtn");
const stopBtn = document.getElementById("stopBtn");
const alwaysBtn = document.getElementById("alwaysBtn");
const exitBtn = document.getElementById("exitBtn");
const backBtn = document.getElementById("backBtn");

const statusText = document.getElementById("statusText");
const phaseText = document.getElementById("phaseText");
const caption = document.getElementById("caption");
const transcript = document.getElementById("transcript");
const globalState = document.getElementById("globalState");

/* audio */
let mediaStream = null;
let recorder = null;
let isRecording = false;
let chunks = [];

let audioContext = null;
let analyser = null;
let dataArray = null;
let rafId = null;

let autoListen = false;

/* Canvas */
const canvas = document.getElementById("wave");
const ctx = canvas.getContext("2d");

function resizeCanvas(){
  canvas.width = canvas.clientWidth;
  canvas.height = canvas.clientHeight;
}
resizeCanvas();
window.addEventListener("resize", resizeCanvas);

/* Waveform animation */
function startVisuals(){
  analyser.fftSize = 2048;
  const len = analyser.fftSize;
  dataArray = new Uint8Array(len);

  function draw(){
    rafId = requestAnimationFrame(draw);
    analyser.getByteTimeDomainData(dataArray);

    ctx.clearRect(0,0,canvas.width,canvas.height);
    ctx.lineWidth = 2;
    ctx.strokeStyle = "rgba(0,224,255,0.9)";
    ctx.beginPath();

    const slice = canvas.width / len;
    let x = 0;

    for(let i=0;i<len;i++){
      const v = dataArray[i] / 128;
      const y = v * canvas.height/2;
      if(i===0) ctx.moveTo(x,y);
      else ctx.lineTo(x,y);
      x += slice;
    }
    ctx.stroke();
  }
  draw();
}

function stopVisuals(){
  if(rafId) cancelAnimationFrame(rafId);
  ctx.clearRect(0,0,canvas.width,canvas.height);
}

/* Transcript */
function pushTranscript(role, text){
  const div = document.createElement("div");
  div.className = "line " + (role==="user" ? "you" : "ai");
  div.innerHTML = `<strong>${role==="user"?"You":"GalaxyX"}:</strong> ${text}`;
  transcript.appendChild(div);
  transcript.scrollTop = transcript.scrollHeight;
}

/* ---- üé§ START RECORDING (MOBILE FIX) ---- */
async function startRecording(maxMs=6000){
  if(isRecording) return;
  isRecording = true;

  globalState.textContent = "Listening";
  statusText.textContent = "Listening...";
  phaseText.textContent = "Recording audio";

  try{
    mediaStream = await navigator.mediaDevices.getUserMedia({ audio:true });
  } catch(e){
    alert("Mic access denied: " + e.message);
    isRecording = false;
    return;
  }

  audioContext = new (window.AudioContext || window.webkitAudioContext)();
  const source = audioContext.createMediaStreamSource(mediaStream);
  analyser = audioContext.createAnalyser();
  source.connect(analyser);

  startVisuals();

  /* AUTO-DETECT BEST MIME TYPE */
  let mime = "audio/webm";
  if(MediaRecorder.isTypeSupported("audio/mp4")) mime = "audio/mp4";
  else if(MediaRecorder.isTypeSupported("audio/ogg")) mime = "audio/ogg";

  recorder = new MediaRecorder(mediaStream, { mimeType:mime });
  chunks = [];

  recorder.ondataavailable = e => { if(e.data.size>0) chunks.push(e.data); };

  recorder.onstop = async ()=>{
    stopVisuals();
    isRecording = false;

    const blob = new Blob(chunks, { type: recorder.mimeType });

    globalState.textContent = "Processing";
    phaseText.textContent = "Transcribing (STT)";
    statusText.textContent = "Processing audio...";

    try{
      const fd = new FormData();
      fd.append("audio", blob, "voice."+mime.split("/")[1]);

      /* STT */
      const sttRes = await fetch(ENDPOINT_STT,{method:"POST",body:fd});
      const sttJson = await sttRes.json();
      const userText = sttJson.text || "";

      if(!userText){
        caption.textContent = "Didn't hear anything. Try again.";
        statusText.textContent = "Idle";
        phaseText.textContent = "Idle";
        globalState.textContent = "Idle";
        if(autoListen) setTimeout(()=>startRecording(),800);
        return;
      }

      pushTranscript("user", userText);
      caption.textContent = `"${userText}"`;

      /* CHAT */
      const chatRes = await fetch(ENDPOINT_CHAT,{
        method:"POST",
        headers:{"Content-Type":"application/json"},
        body:JSON.stringify({text:userText})
      });
      const chatJson = await chatRes.json();
      const aiReply = chatJson.reply || "Sorry, I couldn't reply.";

      pushTranscript("ai", aiReply);
      caption.textContent = aiReply;

      /* TTS */
      statusText.textContent = "Speaking...";
      phaseText.textContent = "Generating audio";
      globalState.textContent = "Speaking";

      const ttsRes = await fetch(ENDPOINT_TTS,{
        method:"POST",
        headers:{"Content-Type":"application/json"},
        body:JSON.stringify({text:aiReply})
      });

      const audioBlob = await ttsRes.blob();
      const url = URL.createObjectURL(audioBlob);
      const audio = new Audio(url);

      audio.onended = ()=>{
        globalState.textContent = "Idle";
        statusText.textContent = "Idle";
        phaseText.textContent = "Idle";
        if(autoListen) setTimeout(()=>startRecording(),800);
      };

      audio.play();
    }
    catch(err){
      caption.textContent = "Error: "+err.message;
    }
    finally {
      try{ mediaStream.getTracks().forEach(t=>t.stop()); }catch(e){}
      try{ audioContext.close(); }catch(e){}
      mediaStream=null; analyser=null; recorder=null;
    }
  };

  recorder.start();

  setTimeout(()=>{
    if(recorder && recorder.state==="recording") recorder.stop();
  }, maxMs);
}

/* STOP */
function stopRecordingNow(){
  try{ if(recorder?.state==="recording") recorder.stop(); }catch(e){}
  try{ mediaStream?.getTracks().forEach(t=>t.stop()); }catch(e){}
  stopVisuals();

  isRecording = false;
  globalState.textContent = "Idle";
  statusText.textContent = "Idle";
  phaseText.textContent = "Idle";
}

/* BUTTON EVENTS */
startBtn.onclick = ()=> startRecording();
stopBtn.onclick = ()=> stopRecordingNow();

alwaysBtn.onclick = ()=>{
  autoListen = !autoListen;
  alwaysBtn.textContent = autoListen ? "üîÅ Auto Listen: On" : "üîÅ Auto Listen: Off";
  alwaysBtn.classList.toggle("neon", autoListen);
  if(autoListen && !isRecording) startRecording();
};

exitBtn.onclick = ()=>{
  stopRecordingNow();
  window.location.href = "index.html";
};

backBtn.onclick = ()=>{
  stopRecordingNow();
  window.location.href = "index.html";
};

/* INIT */
caption.textContent = "Press ‚ñ∂ to start JARVIS.";
</script>

</body>
</html>
